Author:
	Jun Cai, cai.jun@husky.neu.edu
	Vikas Boddu, boddu.v@husky.neu.edu
System:
	Linux

Prereuisites:
	For the Mapreduce:
		1. AWS CLI package (for configuring and running jobs on AWS)
		2. R
		3. Hadoop
		4. Java
		5. ssh (use key authentication so you can do 'ssh localhost' without a password prompt)
	For generating report:
		1. Kintr
		2. Pandoc: (apt-get install pandoc is not enough, need version 1.12.3 or up)
		3. Latex: sudo apt-get install texlive-full
		4. Fonts: sudo apt-get install texlive-fonts-recommended

Build and run the code:
	0. Have correct hadoop paths(both /bin and /sbin folder), setting in PATH environment variable.
	1. Add execute permission to run.sh, main.sh, time.sh in the root folder and also the run.sh file in 'mr/' and 'no_mr/' folder. 
	2. Set JAVA_HOME in .hadoop/hadoop-env.sh and .hadoop/yarn-env.sh to the installation path of java.
	3. Put your AWS credential in line 80 and 81 of 'mr/run.sh'. Also set bucketname in line 136.
	4. Run all the tasks at one using './main.sh SMALL_DATASET_DIR LARGE_DATASET_DIR', where the SMALL_DATASET_DIR and the LARGE_DATASET_DIR are the path to dataset with different size.
	5. Graph and report will be created automatically during the process. The graph file is 'Rplots.pdf'. The report file name is 'report.html'. Also there is a sample report generated by cluster mode named 'generated_report.html' for reference. The report is also available in PDF format. Just change the 'output: html_document' to 'output: pdf_document' in report.Rmd line 5.
	6. We also implement the Scala version of Mapreduce which can be run in local mode. To run the code, replace the input path in line 40 of 'OTPAnalysis.scala' in both 'scala_mr/scala_mr_mean' and 'scala_mr/scala_mr_median' folder. then run 'make run' command.
	
!!Note: if EMR is not working for you, try to check the parameters in 'mr/run.sh', from line 100 to line 111.
